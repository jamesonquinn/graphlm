---
title: "GraphLm Final Project Writeup"
author: "Jameson Quinn and Kyle Mahowald"
date: "April 29, 2015"
output: html_document
---

```{r, include=F}
knitr::opts_chunk$set(message=F, warning=F, error=F, fig.width=9, fig.height=9)
source('plotLm.R')
library(rmarkdown)
```

# Introduction

Perhaps the most common statistical model is linear regression. Often, we want to fit a linear model to data and then evaluate and modify that model. The way that R does that by default, however, is not always as useful as it could be. The plotLm function provides a way to make plotting and evaluating regression models easy and effective.

To demonstrate the features of plotLm, we will first generate some data and show how it is handled by R's default linear regression plotting software. 

```{r}
set.seed(43)
n = 80
x <- data.frame(rmvnorm(n, c(0, 0, 1), .6 * (diag(3) + matrix(.3, 3, 3))))
x$X4 <- c(rep(1, n/2), rep(0, n/2))
y <- x$X1 + 2*x$X2 + 1.2*x$X3^2 + rnorm(n,0,.2) + rnorm(n, x$X4, 1)
x$X4 <- as.factor(x$X4)
l <- lm(y ~ X1 + X2 + X3 + X4 , data=x)
par(mfrow = c(2,2))
plot(l)
par(mfrow = c(1,1))
```

Now let's instead use plotLm.

To run plotLm, we run `by1var` and pass the linear model as an argument along with the variable of interest. Effectively, plotLm will plot the variable of interest against the dependent measure. The gray dots represent the actual data, whereas the red dots are the residuals of the model while holding all non-critical predictors constant.


```{r, results='asis', fig.height=6, fig.width=7, warning=F, message=F, echo=F}
gginc(1:2,by1var(l, "X3", adjustedData=stages(NULL,F), connection=stages(NULL,F), rawData=stages(list(),F), line=stages(NULL,F), loess=stages(NULL,F),rug=stages(list(alpha=0),F)))

```


# Language data

Let's see how plotLm works with a real data set of interest. We'll use some language data on reading times, from the LanguageR package.

First, we load the data and get the columns we want.

```{r}
d <- read.csv('rts.csv')
d$WrittenFrequency <- exp(d$WrittenFrequency)
d$RTnaming <- exp(d$RTnaming)
d <- select(d, RTnaming, Familiarity, Word, AgeSubject, WordCategory, WrittenFrequency, Voice, LengthInLetters)
```

The measure of interest is `RTnaming`, which is a measure of the latency in ms of how long a participant takes to say a word out loud. Here, we have data aggregated by word.

Let's say we want to investigate the effects of `AgeSubject`, `WrittenFrequency`, and `LengthInLetters` in a linear model.

```{r}
###first pass
l <- lm(RTnaming ~ AgeSubject + WrittenFrequency + LengthInLetters , data=d)
```

To plot this data using plotLM, we just use the `by1var.seq` function.

```{r}
by1var.seq(l)
```

We notice something right away: we should take the log of frequency. Let's do that and refit the model.

```{r}
d$WrittenFrequency.log <- log(d$WrittenFrequency)
l <- lm(RTnaming ~ AgeSubject + WrittenFrequency.log + LengthInLetters , data=d)
by1var.seq(l)
```

It's still hard to visualize, so we will try thinning the data. This will not affect the model or the lines of fit shown on the plot. It will just plot fewer data points. To do that, we pass `thin=.1` to the function. This effectively lets us look at 10% of the data.

```{r}
by1var.seq(l, thin=.1)
```

Now we see that we should use the `breakupby` function, which allows us to split a factor of our choice into facets. Here, we do that for `AgeSubject`, which is clearly causing a bimodal distribution.

```{r}
by1var.seq(l, thin=.1, breakupby='AgeSubject')
```

Now we can see each factor separately, while holding the others constant.








